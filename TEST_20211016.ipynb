{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20670755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import IPython\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "\n",
    "#weight_file = 'D:/YOLOTRAFFIC/archive/BX/yolov3_ts_train_7000.weights'\n",
    "weight_file = 'D:/YOLOTRAFFIC/archive/backup/yolov3_ts_train_m_final.weights'\n",
    "cfg_file = 'D:/YOLOTRAFFIC/archive/yolov3_ts_train.cfg'\n",
    "name_file = 'D:/YOLOTRAFFIC/archive/classes.names'\n",
    "weight_file2 = 'D:/YOLOTRAFFIC/archive/yolov4.weights'\n",
    "cfg_file2 = 'D:/YOLOTRAFFIC/archive/yolov4.cfg'\n",
    "name_file2 = 'D:/YOLOTRAFFIC/coco.names'\n",
    "min_confidence = 0.4\n",
    "min_confidence2 = 0.5\n",
    "\n",
    "Prohibitory = [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 15, 16]\n",
    "Danger = [11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "Mandatory = [33, 34, 35, 36, 37, 38, 39, 40]\n",
    "Other = [6, 12, 13, 14, 17, 32, 41, 42]\n",
    "\n",
    "net = cv2.dnn.readNet(weight_file, cfg_file)\n",
    "net2 = cv2.dnn.readNet(weight_file2, cfg_file2)\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "layer_names2 = net2.getLayerNames()\n",
    "output_layers2 = [layer_names2[i[0] - 1] for i in net2.getUnconnectedOutLayers()]\n",
    "\n",
    "classes = []\n",
    "with open(name_file, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "classes2 = []\n",
    "with open(name_file2, 'r') as f:\n",
    "    classes2 = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "model1 = tf.keras.models.load_model(\"C:/Users/HOME/ts_data_Prohibitory_aug1.h5\", compile = True)\n",
    "model2 = tf.keras.models.load_model(\"C:/Users/HOME/ts_data_Danger_aug1.h5\", compile = True)\n",
    "model3 = tf.keras.models.load_model(\"C:/Users/HOME/ts_data_Mandatory_aug1.h5\", compile = True)\n",
    "model4 = tf.keras.models.load_model(\"C:/Users/HOME/ts_data_Other_aug2.h5\", compile = True)    \n",
    "\n",
    "sign_information = [\n",
    "    \"Speed limit (20km/h)\",\n",
    "    \"Speed limit (30km/h)\",\n",
    "    \"Speed limit (50km/h)\",\n",
    "    \"Speed limit (60km/h)\",\n",
    "    \"Speed limit (70km/h)\",\n",
    "    \"Speed limit (80km/h)\",\n",
    "    \"End of speed limit (80km/h)\",\n",
    "    \"Speed limit (100km/h)\",\n",
    "    \"Speed limit (120km/h)\",\n",
    "    \"No passing\",\n",
    "    \"No passing for vechiles over 3.5 metric tons\",\n",
    "    \"Right-of-way at the next intersection\",\n",
    "    \"Priority road\",\n",
    "    \"Yield\",\n",
    "    \"Stop\",\n",
    "    \"No vechiles\",\n",
    "    \"Vechiles over 3.5 metric tons prohibited\",\n",
    "    \"No entry\",\n",
    "    \"General caution\",\n",
    "    \"Dangerous curve to the left\",\n",
    "    \"Dangerous curve to the right\",\n",
    "    \"Double curve\",\n",
    "    \"Bumpy road\",\n",
    "    \"Slippery road\",\n",
    "    \"Road narrows on the right\",\n",
    "    \"Road work\",\n",
    "    \"Traffic signals\",\n",
    "    \"Pedestrians\",\n",
    "    \"Children crossing\",\n",
    "    \"Bicycles crossing\",\n",
    "    \"Beware of ice/snow\",\n",
    "    \"Wild animals crossing\",\n",
    "    \"End of all speed and passing limits\",\n",
    "    \"Turn right ahead\",\n",
    "    \"Turn left ahead\",\n",
    "    \"Ahead only\",\n",
    "    \"Go straight or right\",\n",
    "    \"Go straight or left\",\n",
    "    \"Keep right\",\n",
    "    \"Keep left\",\n",
    "    \"Roundabout mandatory\",\n",
    "    \"End of no passing\",\n",
    "    \"End of no passing by vechiles over 3.5 metric tons\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96983bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prohibitory\n",
      "2\n",
      "Speed limit (50km/h)\n",
      "5 bus\n",
      "7 truck\n",
      "7 truck\n",
      "2 car\n",
      "2 car\n",
      "2 car\n",
      "2 car\n",
      "7 truck\n",
      "0.795020341873169\n"
     ]
    }
   ],
   "source": [
    "random_number = 132\n",
    "#file_name = 'D:/data_road_modi/dc.jpg'\n",
    "file_name = 'D:/data_road_modi/images/0' + str(random_number) + '.jpg'\n",
    "#file_name = 'C:/dd/awe.jpg'\n",
    "#file_name = 'D:/maker_20210926/1dc4.jpg'\n",
    "#file_name = 'D:/YOLOTRAFFIC/archive/home/my_name/ts/00' + str(random_number) + '.jpg'\n",
    "#file_name = 'D:/YOLOTRAFFIC/archive/home/my_name/ts/00077.jpg'\n",
    "a0 = time.time()\n",
    "img = cv2.imread(file_name)\n",
    "imgcopy = cv2.imread(file_name)\n",
    "height, width, channels = img.shape\n",
    "# Detecting objects\n",
    "# https://docs.opencv.org/master/d6/d0f/group__dnn.html\n",
    "blob = cv2.dnn.blobFromImage(img, 0.0392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "box2  = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > min_confidence:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            \n",
    "            boxes.append([x, y, w, h])\n",
    "            box2.append([center_x, center_y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence, 0.4)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        \n",
    "        print(class_ids[i], label)\n",
    "        \n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        #cv2.putText(img, label, (x, y - 10), font, 0.5, (0, 255, 0), 1)  \n",
    "for i in range(len(box2)):\n",
    "    if i in indexes:\n",
    "        x2, y2, w2, h2 = box2[i]\n",
    "        q2 = int(max(h2, w2) * 0.7)\n",
    "        img2 = imgcopy[(y2-q2):(y2+q2), (x2-q2):(x2+q2)]\n",
    "        \n",
    "        \n",
    "        dst = cv2.resize(img2, dsize=(32, 32), interpolation=cv2.INTER_AREA)\n",
    "        dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "        if class_ids[i] == 0:\n",
    "            aaqq = model1.predict(dst.reshape(1, 32, 32, 1))\n",
    "            decode = np.argmax(aaqq, axis = 1)\n",
    "            print(Prohibitory[decode[0]])\n",
    "            print(sign_information[Prohibitory[decode[0]]])\n",
    "            cv2.putText(img, sign_information[Prohibitory[decode[0]]], (x2 - w2 // 2, y2 - h2 // 2 - 10), font, 0.5, (0, 255, 0), 1)  \n",
    "        elif class_ids[i] == 1:\n",
    "            aaqq = model2.predict(dst.reshape(1, 32, 32, 1))\n",
    "            decode = np.argmax(aaqq, axis = 1)\n",
    "            print(Danger[decode[0]])\n",
    "            print(sign_information[Danger[decode[0]]])\n",
    "            cv2.putText(img, sign_information[Danger[decode[0]]], (x2 - w2 // 2, y2 - h2 // 2 - 10), font, 0.5, (0, 255, 0), 1)  \n",
    "        elif class_ids[i] == 2:\n",
    "            aaqq = model3.predict(dst.reshape(1, 32, 32, 1))\n",
    "            decode = np.argmax(aaqq, axis = 1)\n",
    "            print(Mandatory[decode[0]])\n",
    "            print(sign_information[Mandatory[decode[0]]])\n",
    "            cv2.putText(img, sign_information[Mandatory[decode[0]]], (x2 - w2 // 2, y2 - h2 // 2 - 10), font, 0.5, (0, 255, 0), 1)  \n",
    "        elif class_ids[i] == 3:\n",
    "            aaqq = model4.predict(dst.reshape(1, 32, 32, 1))\n",
    "            decode = np.argmax(aaqq, axis = 1)\n",
    "            print(Other[decode[0]])\n",
    "            print(sign_information[Other[decode[0]]])\n",
    "            cv2.putText(img, sign_information[Other[decode[0]]], (x2 - w2 // 2, y2 - h2 // 2 - 10), font, 0.5, (0, 255, 0), 1)  \n",
    "            \n",
    "net2.setInput(blob)\n",
    "outs = net2.forward(output_layers2)\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "box2  = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > min_confidence2:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            \n",
    "            boxes.append([x, y, w, h])\n",
    "            box2.append([center_x, center_y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence2, 0.4)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes and class_ids[i] in [0, 1, 2, 3, 5, 6, 7, 11, 12]:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes2[class_ids[i]])\n",
    "        \n",
    "        print(class_ids[i], label)\n",
    "        \n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(img, label, (x, y - 10), font, 0.5, (0, 0, 255), 1)  \n",
    "\n",
    "\n",
    "cv2.imwrite('D:/R_20211023/' + str(random_number) + '_y26d.jpg', img)\n",
    "\n",
    "a1 = time.time()\n",
    "print(a1-a0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
